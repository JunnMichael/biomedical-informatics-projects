{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Medline Abstracts\n",
    "\n",
    "## My strategy:\n",
    "<ul>\n",
    "<li>For question 1: Read each file > obtain the total number of words from each file > sum the numbers and divide by\n",
    "the total number of files to obtain the average number of words per document</li>\n",
    "<li>For question 2: Read each file > split words into a words list > iterate through each word from the words list > iterate through each letter for each word and obtain its frequency count > store the letter-frequency pair in a dictionary > sort by letter >  extract the pair to print the letter and its\n",
    "frequency count</li>\n",
    "<li>For question 3: Read each file > split words into a words list > iterate through each word from the words list and obtain its frequency count > store the word-frequency pair in a dictionary > sort by frequency count > extract the pair to print out the top 10 least used words with its frequency count with no more than 1 word per frequency</li>\n",
    "</ul>\n",
    "\n",
    "### What is asked:\n",
    "<ol>\n",
    "<li>Obtain the average number of words per document</li>\n",
    "<li>Obtain total count of each 26 alphabet characters from all the documents</li>\n",
    "<li>Obtain the top 10 least used words with no more than 1 word per frequency</li>\n",
    "</ol>\n",
    "\n",
    "### Input:\n",
    "A corpus of medline abstracts. Each abstract is in a text file, with a title and body. The first line of the document is the title.\n",
    "\n",
    "### Output:\n",
    "<ol>\n",
    "<li>Print the average of number of words per document</li>\n",
    "<li>Print the total count of each 26 alphabet characters from all the documents</li>\n",
    "<li>Print the top 10 least used words by ascending order</li>\n",
    "</ol>\n",
    "\n",
    "### Steps:\n",
    "<ol>\n",
    "<li>Load a list of files</li>\n",
    "<li>Read each file, strip the whitespace, then split the words into a words list</li>\n",
    "<li>Create an empty word-frequency dictionary</li>\n",
    "<li>Iterate through each word from the words list</li>\n",
    "<li>Add every new word to word-frequency dictionary and start the count at 1</li>\n",
    "<li>Add 1 to count if word reappears</li>\n",
    "<li>Create an empty letter-frequency dictionary</li>\n",
    "<li>Iterate through each letter for every word from the words list</li>\n",
    "<li>Read each letter in lower case formatting and ignore accented characters</li>\n",
    "<li>Add every new letter to letter-frequency dictionary and start count at 1</li>\n",
    "<li>Add 1 to count if letter reappears</li>\n",
    "<li>Print the average number of words per document by taking total number of words from the words list and dividing by the total number of files</li>\n",
    "<li>Sort, extract each letter-frequency pair from dictionary, and print the letter with its frequency count</li>\n",
    "<li>Sort, extract each word-frequency pair from dictionary, and print only the top 10 least used words and its frequency count in ascending order; skip words with same frequency to only account for one word per frequency</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set path and load list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/opt/class/pubmed/'\n",
    "\n",
    "files = os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating through each file list\n",
    "\n",
    "We are going to read each file, load the abstracts, split the words, and store the words into a words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_words = []\n",
    "\n",
    "for file in files:\n",
    "    open_file = open(path + file, 'r')\n",
    "    split_words += open_file.read().strip().split()\n",
    "    open_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating through each word and letter\n",
    "\n",
    "Now we are going to read each unique word from the words list, obtain its frequency count, and store the word-frequency pair in a dictionary. Then we are going to read each unique letter from each word, obtain its frequency count, and store the letter-frequency pair in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_freq = {}\n",
    "letter_freq = {}\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "for word in split_words:\n",
    "    if word not in word_freq:\n",
    "        word_freq[word] = 1\n",
    "    else:\n",
    "        word_freq[word] += 1\n",
    "    # Now iterate through the letters for each word:    \n",
    "    for abc in word:\n",
    "        letter = abc.lower()\n",
    "        if letter not in letter_freq and letter in alphabet:\n",
    "            letter_freq[letter] = 1\n",
    "        elif letter in letter_freq:\n",
    "            letter_freq[letter] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the average of words/document\n",
    "\n",
    "We will obtain and print the average number of words per document by taking total number of words and dividing by the total number of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average words per document: 198.02 words/documents\n"
     ]
    }
   ],
   "source": [
    "average = len(split_words) / len(files)\n",
    "\n",
    "print(\"Average words per document: {0} words/documents\".format(average))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating through each letter-frequency pair\n",
    "\n",
    "We will extract and print each the letter and its frequency after sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 9162\n",
      "b 1441\n",
      "c 4563\n",
      "d 4238\n",
      "e 13426\n",
      "f 2636\n",
      "g 2061\n",
      "h 4031\n",
      "i 9156\n",
      "j 87\n",
      "k 306\n",
      "l 4675\n",
      "m 3204\n",
      "n 8269\n",
      "o 8014\n",
      "p 3114\n",
      "q 169\n",
      "r 6950\n",
      "s 7256\n",
      "t 9917\n",
      "u 2885\n",
      "v 1350\n",
      "w 1211\n",
      "x 364\n",
      "y 1718\n",
      "z 171\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(letter_freq.items()):\n",
    "    alphabet = key\n",
    "    frequency = value\n",
    "    print(\"{0} {1}\".format(alphabet, frequency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating through each word-frequency pair\n",
    "\n",
    "Finally we will extract and print the top 10 least used words and its frequency after sorting, skipping words with same frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation 1\n",
      "guidelines 2\n",
      "extremity 3\n",
      "literature 4\n",
      "based 5\n",
      "article 6\n",
      "relevant 7\n",
      "approach 8\n",
      "paper 9\n",
      "provide 10\n"
     ]
    }
   ],
   "source": [
    "for item in sorted(word_freq, key=word_freq.get):\n",
    "    if word_freq[item] != frequency:\n",
    "        word = item\n",
    "        frequency = word_freq[item]\n",
    "        print(\"{0} {1}\".format(word, frequency))\n",
    "    elif word_freq[item] == 10:\n",
    "        break\n",
    "    else:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
